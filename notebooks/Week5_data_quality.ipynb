{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45025780",
   "metadata": {},
   "source": [
    "# Week 5 — Data Quality & Data Pipeline (Subte Turnstile Data)\n",
    "\n",
    "This notebook consolidates and cleans the Buenos Aires subway (Subte) turnstile\n",
    "(`molinetes`) data.\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "- Load all raw turnstile CSV files from `data/raw/molinetes/`\n",
    "- Concatenate them into a single unified dataset\n",
    "- Apply reusable data quality checks from `utils/data_quality.py`\n",
    "- Standardize column names and run basic cleaning\n",
    "- Validate schema, row count and basic constraints\n",
    "- Save a clean version of the dataset to `data/processed/`\n",
    "- Produce a short, human-readable data quality summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14324905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('E:/Proyectos/Proyectos GitHub/urban-intelligence-lab/data/raw'),\n",
       " WindowsPath('E:/Proyectos/Proyectos GitHub/urban-intelligence-lab/data/processed'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure project root is on sys.path so we can import `utils`\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from utils.data_quality import (\n",
    "    DataQualityConfig,\n",
    "    run_data_quality_pipeline,\n",
    "    standardize_column_names,\n",
    ")\n",
    "\n",
    "DATA_RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "DATA_RAW_DIR, DATA_PROCESSED_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8d45054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: E:\\Proyectos\\Proyectos GitHub\\urban-intelligence-lab\n",
      "MOLINETES_DIR exists?: True\n",
      "Found 24 CSV files in data/raw/molinetes:\n",
      " - 202401_PAX15min-ABC.csv\n",
      " - 202401_PAX15min-DEH.csv\n",
      " - 202402_PAX15min-ABC.csv\n",
      " - 202402_PAX15min-DEH.csv\n",
      " - 202403_PAX15min-ABC.csv\n",
      " - 202403_PAX15min-DEH.csv\n",
      " - 202404_PAX15min-ABC.csv\n",
      " - 202404_PAX15min-DEH.csv\n",
      " - 202405_PAX15min-ABC.csv\n",
      " - 202405_PAX15min-DEH.csv\n",
      " - 202406_PAX15min-ABC.csv\n",
      " - 202406_PAX15min-DEH.csv\n",
      " - 202407_PAX15min-ABC.csv\n",
      " - 202407_PAX15min-DEH.csv\n",
      " - 202408_PAX15min-ABC.csv\n",
      " - 202408_PAX15min-DEH.csv\n",
      " - 202409_PAX15min-ABC.csv\n",
      " - 202409_PAX15min-DEH.csv\n",
      " - 202410_PAX15min-ABC.csv\n",
      " - 202410_PAX15min-DEH.csv\n",
      " - 202411_PAX15min-ABC.csv\n",
      " - 202411_PAX15min-DEH.csv\n",
      " - 202412_PAX15min-ABC-INCLUYEOTROMODOSDEPAGO.csv\n",
      " - 202412_PAX15min-DEH-INCLUYEOTROMODOSDEPAGO.csv\n"
     ]
    }
   ],
   "source": [
    "MOLINETES_DIR = DATA_RAW_DIR / \"molinetes\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"MOLINETES_DIR exists?:\", MOLINETES_DIR.exists())\n",
    "\n",
    "if MOLINETES_DIR.exists():\n",
    "    files = sorted(MOLINETES_DIR.glob(\"*.csv\"))\n",
    "    print(f\"Found {len(files)} CSV files in data/raw/molinetes:\")\n",
    "    for f in files:\n",
    "        print(\" -\", f.name)\n",
    "else:\n",
    "    files = []\n",
    "    print(\"⚠️ molinetes directory does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c116d99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 202401_PAX15min-ABC.csv with encoding utf-8, shape=(587990, 1)\n",
      "Loaded 202401_PAX15min-DEH.csv with encoding utf-8, shape=(290788, 1)\n",
      "Loaded 202402_PAX15min-ABC.csv with encoding utf-8, shape=(551054, 1)\n",
      "Loaded 202402_PAX15min-DEH.csv with encoding utf-8, shape=(236273, 1)\n",
      "Loaded 202403_PAX15min-ABC.csv with encoding latin1, shape=(599344, 1)\n",
      "Loaded 202403_PAX15min-DEH.csv with encoding latin1, shape=(413562, 1)\n",
      "Loaded 202404_PAX15min-ABC.csv with encoding latin1, shape=(574669, 1)\n",
      "Loaded 202404_PAX15min-DEH.csv with encoding latin1, shape=(459968, 1)\n",
      "Loaded 202405_PAX15min-ABC.csv with encoding latin1, shape=(569524, 1)\n",
      "Loaded 202405_PAX15min-DEH.csv with encoding latin1, shape=(449116, 1)\n",
      "Loaded 202406_PAX15min-ABC.csv with encoding utf-8, shape=(549191, 1)\n",
      "Loaded 202406_PAX15min-DEH.csv with encoding utf-8, shape=(426072, 1)\n",
      "Loaded 202407_PAX15min-ABC.csv with encoding utf-8, shape=(567561, 1)\n",
      "Loaded 202407_PAX15min-DEH.csv with encoding utf-8, shape=(437985, 1)\n",
      "Loaded 202408_PAX15min-ABC.csv with encoding utf-8, shape=(597421, 1)\n",
      "Loaded 202408_PAX15min-DEH.csv with encoding utf-8, shape=(461590, 1)\n",
      "Loaded 202409_PAX15min-ABC.csv with encoding utf-8, shape=(540374, 1)\n",
      "Loaded 202409_PAX15min-DEH.csv with encoding utf-8, shape=(432157, 1)\n",
      "Loaded 202410_PAX15min-ABC.csv with encoding utf-8, shape=(500218, 1)\n",
      "Loaded 202410_PAX15min-DEH.csv with encoding utf-8, shape=(392043, 1)\n",
      "Loaded 202411_PAX15min-ABC.csv with encoding utf-8, shape=(488985, 1)\n",
      "Loaded 202411_PAX15min-DEH.csv with encoding utf-8, shape=(383224, 1)\n",
      "Loaded 202412_PAX15min-ABC-INCLUYEOTROMODOSDEPAGO.csv with encoding utf-8, shape=(526213, 1)\n",
      "Loaded 202412_PAX15min-DEH-INCLUYEOTROMODOSDEPAGO.csv with encoding utf-8, shape=(405118, 1)\n",
      "Combined shape: (11440440, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL;;",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "f5549f63-403a-4fb0-9098-7fef9a390f38",
       "rows": [
        [
         "0",
         "1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Malabia_N_Turn01;Malabia;3;0;0;3",
         null
        ],
        [
         "1",
         "1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Tronador_Turn01;Tronador;1;0;0;1",
         null
        ],
        [
         "2",
         "1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Pellegrini_E_Turn05;Carlos Pellegrini;13;0;0;13",
         null
        ],
        [
         "3",
         "1/1/2024;07:45:00;08:00:00;LineaA;LineaA_Flores_Este_Turn03;Flores;2;0;0;2",
         null
        ],
        [
         "4",
         "1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Dorrego_N_Turn03;Dorrego;1;0;0;1",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL</th>\n",
       "      <th>FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL;;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Malab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Trona...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Pelle...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaA;LineaA_Flore...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Dorre...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL  \\\n",
       "0  1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Malab...                                        \n",
       "1  1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Trona...                                        \n",
       "2  1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Pelle...                                        \n",
       "3  1/1/2024;07:45:00;08:00:00;LineaA;LineaA_Flore...                                        \n",
       "4  1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Dorre...                                        \n",
       "\n",
       "  FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL;;  \n",
       "0                                                NaN                                         \n",
       "1                                                NaN                                         \n",
       "2                                                NaN                                         \n",
       "3                                                NaN                                         \n",
       "4                                                NaN                                         "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not files:\n",
    "    raise RuntimeError(\"No CSV files found in data/raw/molinetes/. Please check the data folder.\")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for f in files:\n",
    "    try:\n",
    "        # First try UTF-8 (default)\n",
    "        df = pd.read_csv(f)\n",
    "        used_encoding = \"utf-8\"\n",
    "    except UnicodeDecodeError:\n",
    "        # Fallback to latin1 / cp1252 style encoding\n",
    "        df = pd.read_csv(f, encoding=\"latin1\")\n",
    "        used_encoding = \"latin1\"\n",
    "\n",
    "    print(f\"Loaded {f.name} with encoding {used_encoding}, shape={df.shape}\")\n",
    "    dfs.append(df)\n",
    "\n",
    "raw_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Combined shape:\", raw_df.shape)\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee31538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11440440 entries, 0 to 11440439\n",
      "Data columns (total 2 columns):\n",
      " #   Column                                                                                     Dtype \n",
      "---  ------                                                                                     ----- \n",
      " 0   FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL    object\n",
      " 1   FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL;;  object\n",
      "dtypes: object(2)\n",
      "memory usage: 174.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL',\n",
       " 'FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL;;']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.info()\n",
    "raw_df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab15b290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/Proyectos/Proyectos GitHub/urban-intelligence-lab/data/raw/molinetes_combined.csv')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_raw_path = DATA_RAW_DIR / \"molinetes_combined.csv\"\n",
    "raw_df.to_csv(combined_raw_path, index=False)\n",
    "\n",
    "combined_raw_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b3f24b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-17 16:17:45] [INFO] utils.data_quality - Standardized column names: ['FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL', 'FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL;;'] -> ['fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total', 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataQualityConfig(name='subte_molinetes_ridership', expected_columns=['fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total', 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;'], non_null_columns=['fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total', 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;'], date_columns=['fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total', 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;'], numeric_columns=[], allowed_values={}, value_ranges={}, unique_keys=[], min_rows=1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize column names the same way the pipeline will do it\n",
    "df_for_config = standardize_column_names(raw_df)\n",
    "\n",
    "standardized_columns = df_for_config.columns.tolist()\n",
    "standardized_columns\n",
    "\n",
    "# Basic heuristics to infer some rules.\n",
    "# You can refine these rules after inspecting the dataset.\n",
    "\n",
    "date_columns = [\n",
    "    c for c in standardized_columns\n",
    "    if \"fecha\" in c.lower() or \"date\" in c.lower()\n",
    "]\n",
    "\n",
    "numeric_columns = df_for_config.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "non_null_columns = [\n",
    "    c for c in standardized_columns\n",
    "    if any(keyword in c.lower() for keyword in [\"linea\", \"line\", \"station\", \"estacion\", \"fecha\", \"date\"])\n",
    "]\n",
    "\n",
    "config = DataQualityConfig(\n",
    "    name=\"subte_molinetes_ridership\",\n",
    "    expected_columns=standardized_columns,\n",
    "    non_null_columns=non_null_columns,\n",
    "    date_columns=date_columns,\n",
    "    numeric_columns=numeric_columns,\n",
    "    allowed_values={\n",
    "        # You can manually add constraints here later, for example:\n",
    "        # \"linea\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"H\"],\n",
    "    },\n",
    "    value_ranges={\n",
    "        # Example (you can refine after inspecting distributions):\n",
    "        # \"validations\": (0, None),\n",
    "    },\n",
    "    unique_keys=[\n",
    "        # Example of potential composite key, to be refined later:\n",
    "        # [\"linea\", \"estacion\", \"fecha\"]\n",
    "    ],\n",
    "    min_rows=1000,  # expecting a reasonably large dataset\n",
    ")\n",
    "\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1484865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-17 16:36:44] [INFO] utils.data_quality - Loading CSV file: E:\\Proyectos\\Proyectos GitHub\\urban-intelligence-lab\\data\\raw\\molinetes_combined.csv\n",
      "E:\\Proyectos\\Proyectos GitHub\\urban-intelligence-lab\\utils\\data_quality.py:80: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raise FileNotFoundError(f\"File does not exist: {path}\")\n",
      "[2025-11-17 16:37:05] [INFO] utils.data_quality - Loaded 11440440 rows and 2 columns\n",
      "[2025-11-17 16:37:05] [INFO] utils.data_quality - Running basic cleaning for dataset 'subte_molinetes_ridership'\n",
      "[2025-11-17 16:37:06] [INFO] utils.data_quality - Standardized column names: ['FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL', 'FECHA;DESDE;HASTA;LINEA;MOLINETE;ESTACION;pax_pagos;pax_pases_pagos;pax_franq;pax_TOTAL;;'] -> ['fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total', 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;']\n",
      "[2025-11-17 16:37:17] [INFO] utils.data_quality - Dropped 3 duplicate rows\n",
      "[2025-11-17 16:37:24] [INFO] utils.data_quality - Saving cleaned dataset to E:\\Proyectos\\Proyectos GitHub\\urban-intelligence-lab\\data\\processed\\subte_molinetes_ridership_clean.csv and E:\\Proyectos\\Proyectos GitHub\\urban-intelligence-lab\\data\\processed\\subte_molinetes_ridership_clean.parquet\n",
      "[2025-11-17 16:38:22] [WARNING] utils.data_quality - Data quality checks found issues for dataset 'subte_molinetes_ridership': [\"Column 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total' has 1672032 null values\", \"Column 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;' has 9768405 null values\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'subte_molinetes_ridership',\n",
       " 'n_rows_before': 11440440,\n",
       " 'n_rows_after': 11440437,\n",
       " 'n_columns': 2,\n",
       " 'issues': [\"Column 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total' has 1672032 null values\",\n",
       "  \"Column 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;' has 9768405 null values\"],\n",
       " 'anomaly_columns': [],\n",
       " 'is_acceptable': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_data_quality_pipeline(\n",
    "    raw_path=combined_raw_path,\n",
    "    processed_dir=DATA_PROCESSED_DIR,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "result.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53fc4daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\do_ch\\AppData\\Local\\Temp\\ipykernel_144\\3975330150.py:2: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clean_df = pd.read_csv(clean_csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11440437, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "aaf7542b-32ce-489f-a82d-a96cd7c491e9",
       "rows": [
        [
         "0",
         "1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Malabia_N_Turn01;Malabia;3;0;0;3",
         null
        ],
        [
         "1",
         "1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Tronador_Turn01;Tronador;1;0;0;1",
         null
        ],
        [
         "2",
         "1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Pellegrini_E_Turn05;Carlos Pellegrini;13;0;0;13",
         null
        ],
        [
         "3",
         "1/1/2024;07:45:00;08:00:00;LineaA;LineaA_Flores_Este_Turn03;Flores;2;0;0;2",
         null
        ],
        [
         "4",
         "1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Dorrego_N_Turn03;Dorrego;1;0;0;1",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total</th>\n",
       "      <th>fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Malab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Trona...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Pelle...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaA;LineaA_Flore...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Dorre...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total  \\\n",
       "0  1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Malab...                                        \n",
       "1  1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Trona...                                        \n",
       "2  1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Pelle...                                        \n",
       "3  1/1/2024;07:45:00;08:00:00;LineaA;LineaA_Flore...                                        \n",
       "4  1/1/2024;07:45:00;08:00:00;LineaB;LineaB_Dorre...                                        \n",
       "\n",
       "  fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;  \n",
       "0                                                NaN                                         \n",
       "1                                                NaN                                         \n",
       "2                                                NaN                                         \n",
       "3                                                NaN                                         \n",
       "4                                                NaN                                         "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_csv_path = DATA_PROCESSED_DIR / \"subte_molinetes_ridership_clean.csv\"\n",
    "clean_df = pd.read_csv(clean_csv_path)\n",
    "\n",
    "print(clean_df.shape)\n",
    "clean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92a98182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: subte_molinetes_ridership\n",
      "Rows before cleaning: 11440440\n",
      "Rows after cleaning: 11440437\n",
      "Number of columns: 2\n",
      "Issues found: 2\n",
      "Main issues:\n",
      "- Column 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total' has 1672032 null values\n",
      "- Column 'fecha;desde;hasta;linea;molinete;estacion;pax_pagos;pax_pases_pagos;pax_franq;pax_total;;' has 9768405 null values\n"
     ]
    }
   ],
   "source": [
    "summary_lines = [\n",
    "    f\"Dataset name: {result.dataset_name}\",\n",
    "    f\"Rows before cleaning: {result.n_rows_before}\",\n",
    "    f\"Rows after cleaning: {result.n_rows_after}\",\n",
    "    f\"Number of columns: {result.n_columns}\",\n",
    "    f\"Issues found: {len(result.issues)}\",\n",
    "]\n",
    "\n",
    "if result.issues:\n",
    "    summary_lines.append(\"Main issues:\")\n",
    "    for issue in result.issues:\n",
    "        summary_lines.append(f\"- {issue}\")\n",
    "\n",
    "if result.anomaly_columns:\n",
    "    summary_lines.append(\n",
    "        f\"Potential numeric anomalies detected in: {', '.join(result.anomaly_columns)}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n\".join(summary_lines))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
